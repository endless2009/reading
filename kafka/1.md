## Kafka中的核心概念

### Broker

一个单独的Kafka Server就是一个Broker，一般情况下可以理解为一个Kafka实例或者一台Kafka服务器。

Broker的主要工作就是接受生产者发过来的消息，分配offset,之后保存在磁盘上；同时，接受消费者、其他Broker的请求，根据其请求类型进行相应处理并返回响应。

### 消息

消息是Kafka中最基本的数据单元。消息由一串字节构成，其中主要有Key和Value构成，key和value也都是byte数组。

key的作用是根据一定的策略，将此消息路由到指定的分区中，这样就可以保证同一key的消息全部写入同一分区中，key可以是null。

消息中真正有效负载时value部分的数据。为了提高网络和存储的效率，消息在发送前会进行压缩。

### Topic & Patition & offset

Topic是用于存储消息的逻辑概念，可以看做是一个消息的集合。每个Topic可以有多个生产者往里推送(Push)消息，也可以有多个消费者来消费(Pull)其中的消息。

每个Topic可以划分为多个分区(Partition)，同一个Topic下的不同分区包含的消息是不同的。每个消息在被添加到分区是，都会被分配一个offset，offset是消息在此分区当中的唯一编号，Kafka通过offset保证消息在分区内的顺序，offset的顺序性不跨分区，即Kafka只保证在同一分区内的消息是有序的；同一Topic的多个分区内的消息，Kafka不保证顺序性。

同一Topic的不同分区会分配在不同的Broker上。分区是Kafka水平扩展性的基础。我们可以通过增加服务器并在其上分配Partition的方式来增加Kafka的并行处理能力。

### Log & Segment

分区在逻辑上对应一个Log，当生产者将消息写入分区是，实际上是写入到了分区对应的Log中。

Log是一个逻辑概念，可以对应到磁盘的一个文件夹。Log由多个Segment组成，每个Segment对应一个日志文件和索引文件。在面对海量数据是，为了避免出现超大文件，每个日志文件的大小是有限制的，当超出限制后则会创建新的Segment，继续对外提供服务。Kafka为了效率，采用顺序I/O，所以只会向最新的Segment追加数据。索引文件采用稀疏索引的方式，文件不大，会在运行时将其内容映射到内存当中，提高索引速度。

### Retention Policy & Log Compaction

Kafka并不会在消息被消费掉之后删除对应的文件，为了避免磁盘被写满，Kafka会配置相应的保留策略(Retention Policy)，以实现周期性删除陈旧的消息。

Kafka中有两种保留策略：
- 一种是根据消息保留的时间，当超过一定时长，就可以被删除。
- 另一种是根据数据大小，当Topic所占的日志文件大小超过一个阈值，则可以开始删除最旧的消息。

Kafka启动了一个后台线程，定期检查是否有可以删除的消息，在粒度上可以灵活配置，全局还是针对某个Topic都可以。

除此之外，Kafka还会进行日志压缩(Log Compaction)。很多场景中，消息的key和value的值之间的对应关系会不断变化，就像数据库中的数据被不段修改，但消费者只关心key对应的最新value值。此时就可以打开日志压缩功能，Kafka使用一个后台线程，定期将相同的key的消息进行合并，只保留最新的value值。

### 副本

Kafka为了保证高可用性，对消息进行了冗余备份，每个Partition可以有多个副本，多个副本中包含的消息是完全一样的(最终一致，并不是每时每刻都一样)。每个分区至少有一个副本，当分区中只有一个副本时，就只有Leader副本，没有Follower副本。

每个分区的副本集合中，都会选举出一个副本作为Leader副本，所有的读写请求都由选举出的Leader副本处理，其他都作为Follower副本，Follower副本仅仅是从Leader副本处把数据拉倒本地之后，同步更新到自己的Log中。一般来说，同一分区的不同副本分布在不同的Broker上，这样当某个Leader所在的Broker宕机后，可以重新选举新的Leader，继续对外提供服务。

### ISR集合

ISR(In-Sync Replica)集合表示的是目前可用且消息量与Leader相差不多的副本集合，是整个副本集合的子集。ISR集合中的副本必须满足一下两个条件：
  1. 副本所在节点必须维持着与ZooKeeper的连接。
  2. 副本最后一条消息的Offset与Leader副本的最后一条消息的Offset之间的差距小于指定阈值。

每个分区的Leader副本会维护此分区的ISR集合。写请求首先由Leader副本处理，之后Follower副本会从Leader上拉取写入的消息，这个过程会有延迟，导致Follower的offset会比Leader慢，只要没有超出阈值就是可以容忍的。如果某个Follower发生异常，例如宕机、长时间GC等导致Kafka卡死或者网络断开连接导致长时间没有拉去消息进行同步，就会违反上述两个条件，从而被Leader提出ISR集合，当Follower副本从异常中恢复以后，会继续与Leader副本进行同步，当Follower副本的offset追上Leader副本的时候，会重新被加入ISR集合中。